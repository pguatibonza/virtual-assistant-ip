{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c38319e0-a05b-4fd7-ad8e-d410b721b84d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Supabase client initialized: <supabase._sync.client.SyncClient object at 0x0000013C7FA70590>\n"
     ]
    }
   ],
   "source": [
    "from langchain_openai import ChatOpenAI, OpenAIEmbeddings, AzureChatOpenAI\n",
    "from langchain_community.tools.tavily_search import TavilySearchResults\n",
    "from dotenv import load_dotenv\n",
    "from supabase import create_client\n",
    "#from langgraph.checkpoint.sqlite import SqliteSaver\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from typing import Annotated\n",
    "from typing_extensions import TypedDict\n",
    "from langgraph.graph import StateGraph, START, END\n",
    "from langgraph.graph.message import add_messages\n",
    "from langchain.schema import Document\n",
    "from langgraph.prebuilt import ToolNode, tools_condition\n",
    "from typing import Literal\n",
    "from typing import List\n",
    "from typing_extensions import TypedDict\n",
    "from langchain.tools.retriever import create_retriever_tool\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.pydantic_v1 import BaseModel, Field\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langgraph.checkpoint.memory import MemorySaver\n",
    "from pprint import pprint\n",
    "from typing import Any,  Literal, Union\n",
    "from langchain_core.messages import  AnyMessage\n",
    "from langchain.schema import AIMessage\n",
    "from langchain_core.prompts import MessagesPlaceholder\n",
    "import logging\n",
    "import os\n",
    "import load_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv()\n",
    "OPENAI_API_KEY = os.getenv(\"OPENAI_API_KEY\")\n",
    "AZURE_OPENAI_API_KEY = os.getenv(\"AZURE_OPENAI_API_KEY\")\n",
    "AZURE_OPENAI_ENDPOINT=os.getenv(\"AZURE_OPENAI_ENDPOINT\")\n",
    "OPENAI_API_VERSION=os.getenv(\"OPENAI_API_VERSION\")\n",
    "\n",
    "vector_store=load_data.load_vector_store()\n",
    "retriever=vector_store.as_retriever(search_kwargs={\"k\":4})\n",
    "chat= AzureChatOpenAI(azure_deployment=\"gpt-4o-rfmanrique\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "chat= AzureChatOpenAI(azure_deployment=\"gpt-4o-rfmanrique\")\n",
    "\n",
    "\n",
    "\n",
    "system=\"\"\"\n",
    "Eres un monitor asistente de la clase de introducción a la programación en Python. Tu función principal es responder dudas conceptuales que los estudiantes tengan sobre los diferentes módulos del curso. El curso está dividido en 4 módulos:\n",
    "\n",
    "Módulo 1: Introducción a la programación\n",
    "\n",
    "En este módulo, los estudiantes aprenden los fundamentos de la programación, cómo funcionan los lenguajes de programación y el proceso de escribir, ejecutar y depurar código.\n",
    "Módulo 2: Condicionales\n",
    "\n",
    "Aquí los estudiantes estudian las estructuras condicionales como if, else, y elif para tomar decisiones en el código.\n",
    "Módulo 3: Bucles\n",
    "\n",
    "En este módulo se cubren bucles for y while, junto con conceptos como control de bucles (break, continue).\n",
    "Módulo 4: Librerías\n",
    "\n",
    "Los estudiantes exploran cómo importar y utilizar librerías en Python, como math o random, y cómo instalar librerías externas.\n",
    "Para responder preguntas de los estudiantes, tendrás como referencia el siguiente contexto tomado de un libro de programación:\n",
    "\n",
    "{context}\n",
    "\n",
    "Tu tarea es usar este contexto para responder de manera precisa, clara y útil a las preguntas. Intenta explicar los conceptos con ejemplos y lenguaje accesible para principiantes, proporcionando respuestas bien estructuradas y fáciles de entender. Si es necesario, usa fragmentos de código simples para ilustrar los conceptos.\n",
    "El usuario se encuentra en el nivel : {level}\n",
    "Utiliza el formato Markdown, incluyendo ‘ para código en línea.\n",
    "\n",
    "Input del usuario : {user_input}\n",
    "\"\"\"\n",
    "\n",
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", system),      \n",
    "        (\"placeholder\",\"{messages}\")\n",
    "    ]\n",
    ")\n",
    "\n",
    "conceptual_agent=prompt|chat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "system = \"\"\"\n",
    "Eres un reformulador de preguntas que convierte una pregunta de entrada en una versión mejorada, optimizada para la búsqueda en una vector store. \n",
    "Observa la entrada y trata de razonar sobre la intención o significado semántico subyacente. La vector store trata tema sobre introducción a la programación.\n",
    "En algunas ocasiones el estudiante hará follow-up questions, por lo que debes reformularla basado en los mensajes anteriores para que pueda entrar a la vector store.\n",
    "Debes ser simple y conciso.\n",
    "\n",
    "La pregunta es : {user_input}\n",
    "\"\"\"\n",
    "\n",
    "re_write_prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", system),\n",
    "        (\"placeholder\",\"{messages}\"),\n",
    "    ]\n",
    ")\n",
    "chat= AzureChatOpenAI(azure_deployment=\"gpt-4o-rfmanrique\")\n",
    "\n",
    "question_rewriter = re_write_prompt | chat "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class State(TypedDict):\n",
    "    messages:Annotated[list,add_messages]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conceptual_assistant(state:State):\n",
    "    user_input=state['messages'][-1]\n",
    "    #Reformula pregunta para vector store\n",
    "    query=question_rewriter.invoke({\"user_input\": user_input, \"messages\":state[\"messages\"]}).content\n",
    "\n",
    "    #Extrae contexto segun el query\n",
    "    context=retriever.invoke(query)\n",
    "\n",
    "    #Responde de acuerdo al contexto\n",
    "    response=conceptual_agent.invoke({\"user_input\":user_input,\"messages\":state[\"messages\"],\"context\":context,\"level\":\"2\"})\n",
    "    return {\"messages\": [response]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph_builder=StateGraph(State)\n",
    "#memory = SqliteSaver.from_conn_string(\":memory:\")\n",
    "memory = MemorySaver()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "graph_builder.add_node(\"conceptual_assistant\",conceptual_assistant)\n",
    "graph_builder.add_edge(\"conceptual_assistant\",END)\n",
    "graph_builder.add_edge(START,\"conceptual_assistant\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph = graph_builder.compile(checkpointer=memory)\n",
    "\n",
    "config={\"configurable\":{\"thread_id\":1}}\n",
    "lista=[\"hola\", \"Quiero saber mas de algebra booleana\"]\n",
    "for i in lista:\n",
    "    for event in graph.stream({\"messages\": (\"user\", i),\"level\":2},config):\n",
    "        for value in event.values():\n",
    "            print(\"Assistant:\", value[\"messages\"][-1].content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "chatbot",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
